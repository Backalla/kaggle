{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.load(\"../input/Sign-language-digits-dataset/X.npy\")\n",
    "y = np.load(\"../input/Sign-language-digits-dataset/Y.npy\")\n",
    "\n",
    "x = x.reshape(x.shape[0], 64, 64, 1)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2062, 64, 64, 1) float32\n",
      "(2062, 10)\n"
     ]
    }
   ],
   "source": [
    "print x.shape, x.dtype\n",
    "print y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "num_filters = [64,128,128,256]\n",
    "strides = [1,2]\n",
    "image_height, image_width, image_channels = 64,64,1\n",
    "learning_rate = 1e-3\n",
    "keep_prob = 0.7\n",
    "num_hidden = 128\n",
    "num_epochs = 300\n",
    "log_every = 10\n",
    "test_every = 10\n",
    "save_every = 50\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def rprint(string):\n",
    "    sys.stdout.write(\"\\r{}\".format(string))\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def conv_layer(name, x, filter_size, input_channels, output_channels, strides=(1, 1), padding='SAME'):\n",
    "    with tf.variable_scope(name):\n",
    "        filters = tf.Variable(tf.random_normal([filter_size[0], filter_size[1], input_channels, output_channels]), dtype=tf.float32, name=\"filters\")\n",
    "        bias = tf.Variable(tf.random_normal([output_channels]),dtype=tf.float32,name=\"bias\")\n",
    "        conv2d_op = tf.nn.conv2d(input=x, filter=filters, strides=[1, strides[0], strides[1], 1], padding=padding)\n",
    "        conv2d_op = tf.nn.bias_add(conv2d_op, bias)\n",
    "        return conv2d_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def max_pool_layer(x, kernel_shape, strides=(2,2), padding=\"SAME\"):\n",
    "    max_pool_op = tf.nn.max_pool(value=x,\n",
    "                                 ksize=[1, kernel_shape[0], kernel_shape[1], 1], \n",
    "                                 strides=[1,strides[0], strides[1], 1], \n",
    "                                 padding=padding, \n",
    "                                 name=\"maxpool\"\n",
    "                                )\n",
    "    return max_pool_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def leaky_relu(x, leakiness=0.0):\n",
    "    return tf.nn.leaky_relu(features=x, alpha=leakiness, name=\"leaky_relu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def build_model(x,dropout_keepprob):\n",
    "    with tf.variable_scope(\"CNN\"):\n",
    "        with tf.variable_scope(\"layer-1\"):\n",
    "            x = conv_layer(\"cnn-1\",x,(3,3),image_channels,num_filters[0])\n",
    "            x = leaky_relu(x,0.01)\n",
    "            x = max_pool_layer(x,(2,2))\n",
    "        print \"layer-1\",x.get_shape().as_list()\n",
    "        \n",
    "        with tf.variable_scope(\"layer-2\"):\n",
    "            x = conv_layer(\"cnn-2\",x,(3,3),num_filters[0],num_filters[1])\n",
    "            x = leaky_relu(x,0.01)\n",
    "            x = max_pool_layer(x,(2,2))\n",
    "        print \"layer-2\",x.get_shape().as_list()\n",
    "        \n",
    "        with tf.variable_scope(\"layer-3\"):\n",
    "            x = conv_layer(\"cnn-3\",x,(3,3),num_filters[1],num_filters[2])\n",
    "            x = leaky_relu(x,0.01)\n",
    "            x = max_pool_layer(x,(2,2))\n",
    "        print \"layer-3\",x.get_shape().as_list()\n",
    "        \n",
    "        with tf.variable_scope(\"layer-4\"):\n",
    "            x = conv_layer(\"cnn-4\",x,(3,3),num_filters[2],num_filters[3])\n",
    "            x = leaky_relu(x,0.01)\n",
    "            x = max_pool_layer(x,(2,2))\n",
    "        print \"layer-4\",x.get_shape().as_list()\n",
    "    \n",
    "    x_shape = x.get_shape().as_list()[1:]\n",
    "    with tf.variable_scope(\"FC\"):\n",
    "        with tf.variable_scope(\"layer-1\"):\n",
    "            weights = tf.Variable(tf.random_normal([np.prod(x_shape),2048]), dtype=tf.float32, name=\"weights-1\")\n",
    "            biases = tf.Variable(tf.random_normal([2048]), dtype=tf.float32, name=\"biases-1\")\n",
    "            \n",
    "            x = tf.reshape(x,[-1,np.prod(x_shape)])\n",
    "            x = leaky_relu(tf.matmul(x,weights)+biases)\n",
    "            x = tf.nn.dropout(x,dropout_keepprob)\n",
    "        \n",
    "        with tf.variable_scope(\"layer-2\"):\n",
    "            weights = tf.Variable(tf.random_normal([2048,1024]), dtype=tf.float32, name=\"weights-2\")\n",
    "            biases = tf.Variable(tf.random_normal([1024]), dtype=tf.float32, name=\"biases-2\")\n",
    "            \n",
    "#             x = tf.reshape(x,[-1,np.prod(x_shape)])\n",
    "            x = leaky_relu(tf.matmul(x,weights)+biases)\n",
    "            x = tf.nn.dropout(x,dropout_keepprob)\n",
    "        \n",
    "        with tf.variable_scope(\"layer-3\"):\n",
    "            weights = tf.Variable(tf.random_normal([1024,10]), dtype=tf.float32, name=\"weights-3\")\n",
    "            biases = tf.Variable(tf.random_normal([10]), dtype=tf.float32,name=\"biases-3\")\n",
    "            \n",
    "            x = tf.matmul(x,weights)+biases\n",
    "            \n",
    "        \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def build_output_ops(logits,labels):\n",
    "    loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=labels, logits=logits))\n",
    "    train_op = tf.train.AdamOptimizer(learning_rate).minimize(loss_op)\n",
    "    correct_prediction = tf.equal(tf.argmax(logits,1), tf.argmax(labels,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    \n",
    "    return [train_op, loss_op, accuracy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer-1 [None, 32, 32, 64]\n",
      "layer-2 [None, 16, 16, 128]\n",
      "layer-3 [None, 8, 8, 128]\n",
      "layer-4 [None, 4, 4, 256]\n",
      "Epoch: 10, Batch: 1600/2062, Loss: 31350434.00, Accuracy: 46.94%%\n",
      "Test Accuracy after 10 epochs: 68.60%\n",
      "Epoch: 20, Batch: 1600/2062, Loss: 5274439.00, Accuracy: 75.51%%\n",
      "Test Accuracy after 20 epochs: 82.63%\n",
      "Epoch: 30, Batch: 1600/2062, Loss: 2697803.50, Accuracy: 85.71%%\n",
      "Test Accuracy after 30 epochs: 84.91%\n",
      "Epoch: 40, Batch: 1600/2062, Loss: 3275653.25, Accuracy: 81.63%\n",
      "Test Accuracy after 40 epochs: 85.22%\n",
      "Epoch: 50, Batch: 1600/2062, Loss: 1842920.50, Accuracy: 89.80%\n",
      "Test Accuracy after 50 epochs: 87.68%\n",
      "Epoch: 60, Batch: 1600/2062, Loss: 1752399.62, Accuracy: 89.80%\n",
      "Test Accuracy after 60 epochs: 89.37%\n",
      "Epoch: 70, Batch: 1600/2062, Loss: 1189098.50, Accuracy: 91.84%\n",
      "Test Accuracy after 70 epochs: 87.54%\n",
      "Epoch: 80, Batch: 1600/2062, Loss: 2029267.25, Accuracy: 89.80%\n",
      "Test Accuracy after 80 epochs: 90.98%\n",
      "Epoch: 90, Batch: 1600/2062, Loss: 1013782.75, Accuracy: 89.80%\n",
      "Test Accuracy after 90 epochs: 90.04%\n",
      "Epoch: 100, Batch: 1600/2062, Loss: 669431.81, Accuracy: 93.88%%\n",
      "Test Accuracy after 100 epochs: 91.47%\n",
      "Epoch: 110, Batch: 1600/2062, Loss: 408840.75, Accuracy: 95.92%%\n",
      "Test Accuracy after 110 epochs: 90.58%\n",
      "Epoch: 120, Batch: 1600/2062, Loss: 228849.06, Accuracy: 95.92%%\n",
      "Test Accuracy after 120 epochs: 91.69%\n",
      "Epoch: 130, Batch: 1600/2062, Loss: 2041248.00, Accuracy: 87.76%\n",
      "Test Accuracy after 130 epochs: 89.64%\n",
      "Epoch: 140, Batch: 1600/2062, Loss: 631754.44, Accuracy: 95.92%%\n",
      "Test Accuracy after 140 epochs: 90.98%\n",
      "Epoch: 150, Batch: 1600/2062, Loss: 10668.08, Accuracy: 97.96%%%\n",
      "Test Accuracy after 150 epochs: 93.48%\n",
      "Epoch: 160, Batch: 1600/2062, Loss: 1048436.75, Accuracy: 93.88%\n",
      "Test Accuracy after 160 epochs: 92.81%\n",
      "Epoch: 170, Batch: 1600/2062, Loss: 0.00, Accuracy: 100.00%.88%%\n",
      "Test Accuracy after 170 epochs: 92.86%\n",
      "Epoch: 180, Batch: 1600/2062, Loss: 1816975.00, Accuracy: 93.88%\n",
      "Test Accuracy after 180 epochs: 92.81%\n",
      "Epoch: 190, Batch: 1600/2062, Loss: 3007148.75, Accuracy: 89.80%\n",
      "Test Accuracy after 190 epochs: 95.04%\n",
      "Epoch: 200, Batch: 1600/2062, Loss: 0.00, Accuracy: 100.00%44%%%\n",
      "Test Accuracy after 200 epochs: 94.60%\n",
      "Epoch: 210, Batch: 1600/2062, Loss: 0.00, Accuracy: 100.00%44%%%\n",
      "Test Accuracy after 210 epochs: 94.60%\n",
      "Epoch: 220, Batch: 1600/2062, Loss: 494921.62, Accuracy: 97.96%%\n",
      "Test Accuracy after 220 epochs: 95.31%\n",
      "Epoch: 230, Batch: 1600/2062, Loss: 111717.23, Accuracy: 97.96%%\n",
      "Test Accuracy after 230 epochs: 94.87%\n",
      "Epoch: 240, Batch: 1600/2062, Loss: 672701.62, Accuracy: 97.96%%\n",
      "Test Accuracy after 240 epochs: 93.03%\n",
      "Epoch: 250, Batch: 1600/2062, Loss: 0.00, Accuracy: 100.00%44%%%\n",
      "Test Accuracy after 250 epochs: 94.37%\n",
      "Epoch: 260, Batch: 1600/2062, Loss: 123327.67, Accuracy: 97.96%%\n",
      "Test Accuracy after 260 epochs: 95.09%\n",
      "Epoch: 270, Batch: 1600/2062, Loss: 92231.51, Accuracy: 97.96%%%\n",
      "Test Accuracy after 270 epochs: 93.70%\n",
      "Epoch: 280, Batch: 1600/2062, Loss: 73943.34, Accuracy: 97.96%%%\n",
      "Test Accuracy after 280 epochs: 92.99%\n",
      "Epoch: 290, Batch: 1600/2062, Loss: 422534.78, Accuracy: 95.92%%\n",
      "Test Accuracy after 290 epochs: 95.27%\n",
      "Epoch: 300, Batch: 1600/2062, Loss: 979792.31, Accuracy: 97.96%%\n",
      "Test Accuracy after 300 epochs: 95.27%\n"
     ]
    }
   ],
   "source": [
    "X = tf.placeholder(tf.float32, shape=[None, image_height, image_width, image_channels], name=\"inputs\")\n",
    "Y = tf.placeholder(tf.float32, shape=[None, 10], name=\"labels\")\n",
    "dropout_keepprob = tf.placeholder_with_default(1.0,shape=(), name=\"dropout_keepprob\")\n",
    "\n",
    "logits = build_model(X,dropout_keepprob)\n",
    "train_ops = build_output_ops(logits,Y)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for epoch in range(1,num_epochs+1):\n",
    "        for batch_index in range(0,len(x_train),batch_size):\n",
    "            feed_dict = {X:x_train[batch_index:batch_index+batch_size], Y:y_train[batch_index:batch_index+batch_size], dropout_keepprob:keep_prob}\n",
    "            _, loss_val, accuracy_val = sess.run(train_ops, feed_dict=feed_dict)\n",
    "            rprint(\"Epoch: {}, Batch: {:0>4d}/{}, Loss: {:.2f}, Accuracy: {:.2%}\".format(epoch,batch_index,len(x),loss_val,accuracy_val))\n",
    "        if epoch%test_every==0:\n",
    "            accuracies = []\n",
    "            for batch_index in range(0,len(x_test),batch_size):\n",
    "                feed_dict = {X:x_test[batch_index:batch_index+batch_size], Y:y_test[batch_index:batch_index+batch_size]}\n",
    "                accuracy_val = sess.run(train_ops[2], feed_dict=feed_dict)\n",
    "                accuracies.append(accuracy_val)\n",
    "            print\n",
    "            print \"Test Accuracy after {} epochs: {:.2%}\".format(epoch,np.mean(accuracies))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
